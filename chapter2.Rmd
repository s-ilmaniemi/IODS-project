# Exercise 2: Data analysis

```{r}
date()
```
### Data description 

```{r}
lrn14<-read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/learning2014.txt", , sep=",", header=TRUE)

dim(lrn14)

str(lrn14)

```

The dataset __lerning2014__ includes 7 different variables and 166 observations. Observations represent students. Besides background variables gender and age, the dataset includes information how student scored in a exam (variable _points_) and their attidude towards statistics on a scale 1 to 5 (_attitude_). The variable _deep_ is the average points on a scale 1 to 5 from questions concerning deep learning approaches. Variables _stra_ and _surf_ include information on average points from questions about strategic learning and surface learning approaches.

More information about the original dataset, that was used to form this dataset, can be found [here](https://www.mv.helsinki.fi/home/kvehkala/JYTmooc/JYTOPKYS3-meta.txt)

### A graphical overview of the data and summary statistics

```{r}
library(GGally)
library(ggplot2)

p <- ggpairs(lrn14, mapping = aes(col =gender, alpha = 0.3), lower = list(combo = wrap("facethist", bins = 20)))

p

summary(lrn14)

```

From the graph above we can see the distrubutions of different variables by gender. Below the graph there are summary statistics for different variables. The avereage age of study participants is 25.51 years. Majority of participants are women. _Attitude_ variable has the strongest correlation with exam points and the scatter plot of these two variables also indicate that there may be some kind assocation between these variables.

### Linear regression models

```{r}
model1 <- lm(points ~ attitude + stra + surf, data = lrn14)

summary(model1)

model2 <- lm(points ~ attitude , data = lrn14)

summary(model2)

```

We choose variables _attitude, _stra_ and _surf_ as independents variables to fit a linear regression model where _points_ i.e. exam points is the dependent variable. The chosen independent variables were the most correlated variables with the dependent variable. From Model 1 summary we can see that only _attitude_ has a statistically significant coefficient (3.3952) as its p-value <0.0001. With low p-value we can reject the null hypothesis that the coefficent is zero. When we fit Model 2 without _stra_ and _surf_ the coefficent for _attitude_ is still significant and its value (3.5255) is close to that in Model 1. 

The multiple R-squared tells us how much our models explain the variation in _points_. Multiple R-squared are quite close to each other in both models (Model 1 0.2074 and Model 2 0.1906 ) so roughly both models explain approx. 20% of the varioation in _points_. In Model 2 with a single independent variable the miltiple R-squared is basically the square of correlation coefficient between the independent and the dependent variable.

### Diagnostic plots

```{r}
par(mfrow =c(2,2))
plot(model2, which = c(1,2,5) )

```


From the QQ plot we can see that the residuals reasonable well fall in with the line which would indicate that the assumption of normality of error terms are not violated.


From the plot where residuals and fitted values from the model are plotted we can see that there is no clear pattern. The size of error term does not depend on the independent variables which indicates that the constant variance of error term assumption is not violated.

The leverage plot helps us to estimate if there are influential outliers in our data that affect out estimation results. From our leverage plot we see that there are no influential outliers, the x-axis scale is very low.
